#
#  Copyright (c) 2023-2024 - Restate Software, Inc., Restate GmbH
#
#  This file is part of the Restate SDK for Python,
#  which is released under the MIT license.
#
#  You can find a copy of the license in file LICENSE in the root
#  directory of this repository or package, or at
#  https://github.com/restatedev/sdk-typescript/blob/main/LICENSE
#
"""
This module contains the optional OpenAI integration for Restate.
"""

import dataclasses

from agents import (
    Usage,
    Model,
    RunContextWrapper,
    AgentsException,
    RunConfig,
    TContext,
    RunResult,
    Agent,
    ModelBehaviorError,
    ModelSettings,
)
from agents.models.multi_provider import MultiProvider
from agents.items import TResponseStreamEvent, TResponseOutputItem, ModelResponse
from agents.memory.session import SessionABC
from agents.items import TResponseInputItem
from agents.run import (
    AgentRunner,
    DEFAULT_AGENT_RUNNER,
)
from datetime import timedelta
from typing import List, Any, AsyncIterator, Optional, cast
from pydantic import BaseModel

from restate.exceptions import SdkInternalBaseException
from restate.extensions import current_context
from restate import RunOptions, ObjectContext, TerminalError

@dataclasses.dataclass
class LlmRetryOpts:
    max_attempts: Optional[int] = 10
    """Max number of attempts (including the initial), before giving up.

    When giving up, the LLM call will throw a `TerminalError` wrapping the original error message."""
    max_duration: Optional[timedelta] = None
    """Max duration of retries, before giving up.

    When giving up, the LLM call will throw a `TerminalError` wrapping the original error message."""
    initial_retry_interval: Optional[timedelta] = timedelta(seconds=1)
    """Initial interval for the first retry attempt.
    Retry interval will grow by a factor specified in `retry_interval_factor`.

    If any of the other retry related fields is specified, the default for this field is 50 milliseconds, otherwise restate will fallback to the overall invocation retry policy."""
    max_retry_interval: Optional[timedelta] = None
    """Max interval between retries.
    Retry interval will grow by a factor specified in `retry_interval_factor`.

    The default is 10 seconds."""
    retry_interval_factor: Optional[float] = None
    """Exponentiation factor to use when computing the next retry delay.

    If any of the other retry related fields is specified, the default for this field is `2`, meaning retry interval will double at each attempt, otherwise restate will fallback to the overall invocation retry policy."""


# The OpenAI ModelResponse class is a dataclass with Pydantic fields.
# The Restate SDK cannot serialize this. So we turn the ModelResponse int a Pydantic model.
class RestateModelResponse(BaseModel):
    output: list[TResponseOutputItem]
    """A list of outputs (messages, tool calls, etc) generated by the model"""

    usage: Usage
    """The usage information for the response."""

    response_id: str | None
    """An ID for the response which can be used to refer to the response in subsequent calls to the
    model. Not supported by all model providers.
    If using OpenAI models via the Responses API, this is the `response_id` parameter, and it can
    be passed to `Runner.run`.
    """

    def to_input_items(self) -> list[TResponseInputItem]:
        return [it.model_dump(exclude_unset=True) for it in self.output]  # type: ignore


class DurableModelCalls(MultiProvider):
    """
    A Restate model provider that wraps the OpenAI SDK's default MultiProvider.
    """

    def __init__(self, llm_retry_opts: LlmRetryOpts | None = None):
        super().__init__()
        self.llm_retry_opts = llm_retry_opts

    def get_model(self, model_name: str | None) -> Model:
        return RestateModelWrapper(super().get_model(model_name or None), self.llm_retry_opts)


class RestateModelWrapper(Model):
    """
    A wrapper around the OpenAI SDK's Model that persists LLM calls in the Restate journal.
    """

    def __init__(self, model: Model, llm_retry_opts: LlmRetryOpts | None = LlmRetryOpts()):
        self.model = model
        self.model_name = "RestateModelWrapper"
        self.llm_retry_opts = llm_retry_opts

    async def get_response(self, *args, **kwargs) -> ModelResponse:
        async def call_llm() -> RestateModelResponse:
            resp = await self.model.get_response(*args, **kwargs)
            # convert to pydantic model to be serializable by Restate SDK
            return RestateModelResponse(
                output=resp.output,
                usage=resp.usage,
                response_id=resp.response_id,
            )

        ctx = current_context()
        if ctx is None:
            raise RuntimeError("No current Restate context found, make sure to run inside a Restate handler")
        result = await ctx.run_typed(
            "call LLM",
            call_llm,
            RunOptions(
                max_attempts=self.llm_retry_opts.max_attempts,
                max_duration=self.llm_retry_opts.max_duration,
                initial_retry_interval=self.llm_retry_opts.initial_retry_interval,
                max_retry_interval=self.llm_retry_opts.max_retry_interval,
                retry_interval_factor=self.llm_retry_opts.retry_interval_factor,
            ),
        )
        # convert back to original ModelResponse
        return ModelResponse(
            output=result.output,
            usage=result.usage,
            response_id=result.response_id,
        )

    def stream_response(self, *args, **kwargs) -> AsyncIterator[TResponseStreamEvent]:
        raise TerminalError("Streaming is not supported in Restate. Use `get_response` instead.")


class RestateSession(SessionABC):
    """Restate session implementation following the Session protocol."""

    def __init__(self):
        self._items: List[TResponseInputItem] | None = None

    def _ctx(self) -> ObjectContext:
        return cast(ObjectContext, current_context())

    async def _load_items_if_needed(self) -> None:
        """Load items from context if not already loaded."""
        if self._items is None:
            self._items = await self._ctx().get("items", type_hint=List[TResponseInputItem]) or []

    async def get_items(self, limit: int | None = None) -> List[TResponseInputItem]:
        """Retrieve conversation history for this session."""
        await self._load_items_if_needed()
        if limit is not None:
            return self._items[-limit:]
        return self._items.copy()

    async def add_items(self, items: List[TResponseInputItem]) -> None:
        """Store new items for this session."""
        await self._load_items_if_needed()
        self._items.extend(items)

    async def pop_item(self) -> TResponseInputItem | None:
        """Remove and return the most recent item from this session."""
        await self._load_items_if_needed()
        if self._items:
            return self._items.pop()
        return None

    def flush(self) -> None:
        """Flush the session items to the context."""
        self._ctx().set("items", self._items)

    async def clear_session(self) -> None:
        """Clear all items for this session."""
        self._items = []
        self._ctx().clear("items")


class AgentsTerminalException(AgentsException, TerminalError):
    """Exception that is both an AgentsException and a restate.TerminalError."""

    def __init__(self, *args: object) -> None:
        super().__init__(*args)


class AgentsSuspension(AgentsException, SdkInternalBaseException):
    """Exception that is both an AgentsException and a restate SdkInternalBaseException."""

    def __init__(self, *args: object) -> None:
        super().__init__(*args)


def raise_terminal_errors(context: RunContextWrapper[Any], error: Exception) -> str:
    """A custom function to provide a user-friendly error message."""
    # Raise terminal errors and cancellations
    if isinstance(error, TerminalError):
        # For the agent SDK it needs to be an AgentsException, for restate it needs to be a TerminalError
        # so we create a new exception that inherits from both
        raise AgentsTerminalException(error.message)

    if isinstance(error, ModelBehaviorError):
        return f"An error occurred while calling the tool: {str(error)}"

    raise error


def continue_on_terminal_errors(context: RunContextWrapper[Any], error: Exception) -> str:
    """A custom function to provide a user-friendly error message."""
    # Raise terminal errors and cancellations
    if isinstance(error, TerminalError):
        # For the agent SDK it needs to be an AgentsException, for restate it needs to be a TerminalError
        # so we create a new exception that inherits from both
        return f"An error occurred while running the tool: {str(error)}"

    if isinstance(error, ModelBehaviorError):
        return f"An error occurred while calling the tool: {str(error)}"

    raise error


class DurableRunner:
    """
    A wrapper around Runner.run that automatically configures RunConfig for Restate contexts.

    This class automatically sets up the appropriate model provider (DurableModelCalls) and
    model settings, taking over any model and model_settings configuration provided in the
    original RunConfig.
    """

    @staticmethod
    async def run(
        starting_agent: Agent[TContext],
        input: str | list[TResponseInputItem],
        **kwargs,
    ) -> RunResult:
        """
        Run an agent with automatic Restate configuration.

        Returns:
            The result from Runner.run
        """

        # Set persisting model calls
        llm_retry_opts = kwargs.get("llm_retry_opts", None)
        run_config = kwargs.pop("run_config", RunConfig())
        run_config = dataclasses.replace(run_config, model_provider=DurableModelCalls(llm_retry_opts))

        # Disable parallel tool calls
        model_settings = run_config.model_settings
        if model_settings is None:
            model_settings = ModelSettings(parallel_tool_calls=False)
        else:
            model_settings = dataclasses.replace(
                model_settings,
                parallel_tool_calls=False,
            )
        run_config = dataclasses.replace(
            run_config,
            model_settings=model_settings,
        )

        runner = DEFAULT_AGENT_RUNNER or AgentRunner()
        try:
            result = await runner.run(starting_agent=starting_agent, input=input, run_config=run_config, **kwargs)
        finally:
            # Flush session items to Restate
            session = kwargs.get("session", None)
            if session is not None and isinstance(session, RestateSession):
                session.flush()

        return result
